---
title: 理解TF-IDF
date: 2020/07/15
update: 2020/08/07
tags:
  - NLP
  - TF-IDF
---

TF-IDF(term frequency-inverse document frequency) 是TF(term frequency, 词频)与IDF(inverse document frequency, 你文档频率)的组合。其本身只使用来衡量一个词在某个数据集中的重要程度，常用于使用这些词来对文档做分类，或者类似聚类的应用。

<!--more-->

从数学公事上应该是
$$
tf_{i,j} = \frac{n_{i,j}}{\sum_k{n_{k,j}}}
$$

$$
idf_i = log{\frac{|D|}{|{j: t_i\in{d_j}}|}}
$$

上面的式子中$j$都是指文档的编号，$i$是指字符的编号。
$$
tfidf_{i,j} = tf_{i,j} \times idf_i
$$
那么`tf-idf`就是他们的乘积

不足之处：

> tf-idf算法是建立在这样一个假设之上的：对区别文档最有意义的词语应该是那些在文档中出现频率高，而在整个文档集合的其他文档中出现频率少的词语，所以如果特征空间坐标系取tf词频作为测度，就可以体现同类文本的特点。另外考虑到单词区别不同类别的能力，tf-idf法认为一个单词出现的文本频数越小，它区别不同类别文本的能力就越大。因此引入了逆文本频度idf的概念，以tf和idf的乘积作为特征空间坐标系的取值测度，并用它完成对权值tf的调整，调整权值的目的在于突出重要单词，抑制次要单词。但是在本质上idf是一种试图抑制雜訊的加权，并且单纯地认为文本頻率小的单词就越重要，文本頻率大的单词就越无用，显然这并不是完全正确的。idf的简单结构并不能有效地反映单词的重要程度和特征词的分布情况，使其无法很好地完成对权值调整的功能，所以tf-idf法的精度并不是很高。 
>
> 此外，在tf-idf算法中并没有体现出单词的位置信息，对于Web文档而言，权重的计算方法应该体现出HTML的结构特征。特征词在不同的标记符中对文章内容的反映程度不同，其权重的计算方法也应不同。因此应该对于处于网页不同位置的特征词分别赋予不同的系数，然后乘以特征词的词频，以提高文本表示的效果。

简单来说：

1. `tf-idf`本身就建立在那些`tf-idf`越大的词对于这个文档的分类依据越大，但是实际上这个假设本身就有点牵强
2. 没有考虑单词出现的位置信息

参考资料：[wikipedia](https://zh.wikipedia.org/wiki/Tf-idf)